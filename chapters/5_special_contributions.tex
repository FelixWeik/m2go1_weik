\chapter{Special Contributions}
\label{ch:special_contributions}

\section{Go Environment Variables}
\label{sec:go_environment_variables}
This section is executed on a Unix-based system, in the author's case it's Ubuntu.

\subsection{Installation}
During the go installation, one needs to add paths to the environment variables.
To add the paths add \texttt{export PATH\=\$PATH\:\/usr\/local\/go\/bin} 
to the \texttt{\$HOME/.profile} for user-wide installation or to \texttt{/etc/profile} for a system-wide installation.
But what is the difference between both files and what exactly does this extra variable in the file do?

\subsection{The .profile File}
This file is used to set environment variables and configurations for the shell.
It contains the file paths for commands the system will check for instead of the user typing the full path to the file every time he wants to execute it.
When a user logs into the system, the file is executed to initialize the environment for the user's session.
The file is located in the user's home directory and is hidden by default.

The usual setup is separated into two files:
\begin{enumerate}
    \item System-wide configuration:
        Files like \texttt{/etc/profile} are used to set up the environment for all users.
        These files are executed when any user logs in.
    \item User-specific configuration:
        Each user has their profile configuration file.
        This file is located in the user's home directory like \texttt{\$HOME/.profile} or \texttt{\$HOME/.bashrc}.
        These files are executed when the specific user logs in.
\end{enumerate}

\subsection{PATH Variables}
If one does not include a \texttt{PATH} variable in her system, the shell will only search for executable files in the system-wide paths defined in the default \texttt{PATH} variable.
If the binary is not located in these system-wide paths, the file will not be able to be executed correctly without providing the complete path.
Adding a directory to the \texttt{PATH} allows the shell to search in custom directories for executable (or binary) files.
Therefore, commands and programs can be executed without specifying the full path.

In the example above, the \texttt{PATH} variable is extended by the path to the go binaries, enabling go files in the \texttt{PATH} to be executed without specifying the full path.

\section{Go Repositories}
\label{sec:go_repositories}
This section explains the benefits and use cases of repositories in go.
The go-application \texttt{CarRentalCLI} is used as an example.

\subsection{Repositories}
CarRentalCLI uses repositories to access the data.
These repositories are located on the logic layer.
It implements the interface \texttt{CarRentalRepositoryInterface} which provides the signatures of the data accessing functions.
\texttt{CarRentalRepository} then implements these specified functions, the constructor, and lists containing the application's data as specified in the model package.

All of the implemented functions are used to manipulate data in the lists and the yaml files.
Therefore the repository also has access to the yaml mappers and entities.

\subsubsection*{Implementation in CarRentalCLI}
The \texttt{CarRentalRepositoryInterface} is implemented by \texttt{CarRentalRepository}.
This repository is then given to \texttt{CarRentalOperations} in the main function.
The operations object then is used in the cli to call the repository's functions and lists.

\subsubsection*{Benefits}
While this seems counterintuitive at first, this implementation hierarchy provides some great benefits.
\begin{enumerate}
    \item Abstraction: The cli does not need to know how the data is accessed.
          It only needs to know that the data is accessed by the repository.
          This allows for easy changes in the data-accessing process.
    \item Flexibility: The operations object and therefore the cli can be used with different repositories.
          This allows for easy changes in the data-accessing process.
          Furthermore, the functionality can be switched out if necessary.
    \item Scalability: The repository can be extended by adding new functions.
          The operations and the cli can then use these new functions without changing the cli itself.
    \item Encapsulation: The cli does not need to know how the data is accessed.
          It only needs to know that the data is accessed by the repository.
          This allows for easy changes in the data-accessing process.
    \item Maintainability: The repository and therefore the cli can be maintained by fixing functions.
    \item Testing: Testing can be easily realized by implementing a mock repository.
          This is further explained in the following section on mock-repositories \ref*{sec:mock_repositories}.
\end{enumerate}

\subsection{Mock-Repositories}
\label{sec:mock_repositories}
A mock repository is a repository that implements the repository interface but does not access the data.
It usually is located on the same layer as the actual repository yet in a different package.

The mock repository does not import any other packages or modules besides the repository interface or helper packages.
It only implements the repository interface and provides the lists and functions needed for executing correctly.
Furthermore, it does not implement a constructor, since it does not need to initialize any data.
This is usually done in the test file to create the needed testing environment.

\subsubsection*{Implementation in CarRentalCLI}
The mock repository implements the \texttt{CarRentalRepositoryInterface} and provides the lists and functions needed for executing correctly.
Yet, it does not implement a constructor as the actual repository does.
This is done in the test file to create the needed testing environment.

This mock repository does not access any yaml mapper or write data to any yaml file.
It solely writes to the mock repository's lists and manipulates them.

To implement the lists it needs to import the according models.
Apart from that, it does not import any other packages or modules.

\subsubsection*{Benefits}
This process provides similar benefits as the actual repository but also has some great benefits for testing.
\begin{enumerate}
    \item Readability: Tests and code of the actual application are separated.
          This allows for better readability and overview.
    \item No new Dependencies and Datafiles: By solely accessing the lists in the mock repository, nothing is written to the yaml files.
          Therefore, nothing needs to be cleaned up after testing is done.
          Furthermore, testing cannot corrupt the data in the yaml files or block the execution of the application.
\end{enumerate}

\subsubsection*{Example}
Let's take a closer look at the differences between an actual repository and the mock repository, by taking a closer look at the \texttt{CarRentalCLI} program and its repositories.

As a first example the \texttt{GetCar} function is used.
This function takes the car ID as a parameter and returns the car with the corresponding ID.

The code from the mock repository is shown in \autoref{lst:mock_repository_get_car_function}.
Code from the actual repository is shown in \autoref{lst:repository_get_car_function}.

The mock repository solely iterates over the list of cars and returns the car if it is found.
Contrary, the actual repository iterates over the list of car persistence entities and converts them to cars.
This is done by using the yaml mapper.
The mock repository does not need to import the yaml mapper or the car persistence entity, since it solely operates in its own, non-persistent lists.

\begin{lstlisting}[
      float=h,
      style=kit-cm,
      caption={Mock Repository GetCar Function},
      label={lst:mock_repository_get_car_function},
      language=Golang,
]
func (repository MockCarRentalRepository) GetCar(carID string) (model.Car, error) {
for _, car := range repository.Cars {
      if car.ID == carID {
            return car, nil
      }
}
return model.Car{}, fmt.Errorf("Could not find car")
}
\end{lstlisting}

\begin{lstlisting}[
      float=h,
      style=kit-cm,
      caption={Repository GetCar Function},
      label={lst:repository_get_car_function},
      language=Golang,
]
func (repository CarRentalRepository) GetCar(carID string) (model.Car, error) {
for _, car := range repository.Cars {
      if car.ID == carID {
            return YAMLMapper.ConvertCarPersistenceEntityToCar(car), nil
      }
}

return model.Car{}, fmt.Errorf("Could not find car")
}
\end{lstlisting}

The second example is the \texttt{CreateRental} function.
The function takes a rental as a parameter and adds it to the list of rentals.
It therefore provides the functionality to save newly created models to the database.

The code from the mock repository is shown in \autoref{lst:mock_repository_create_rental_function}.
Code from the actual repository is shown in \autoref{lst:repository_create_rental_function}.

The mock repository solely appends the rental to the list of rentals.
Therefore no further imports besides the Rental model are needed.

Contrary, the actual repository converts the rental to a rental persistence entity before appending it to the list of rentals.
This is done by using the Rental's yaml mapper.
After that, the \texttt{SaveData} function is called to save the data to the yaml file.
Therefore the actual repository needs to import the yaml mapper and the rental persistence entity just for this function.

This enables the repository to save the data persistently by writing it to the yaml file while the mock repository stores its data only during execution.
In the specific use cases of each repository, running the application for the actual repository and testing for the mock repository, this different functionality is of great worth as mentioned above.

\begin{lstlisting}[
      float=h,
      style=kit-cm,
      caption={Mock Repository CreateRental Function},
      label={lst:mock_repository_create_rental_function},
      language=Golang,
]
func (repository MockCarRentalRepository) CreateRental(newRental model.Rental) error {
repository.Rentals = append(repository.Rentals, newRental)
return nil
}
\end{lstlisting}

\begin{lstlisting}[
      float=h,
      style=kit-cm,
      caption={Repository CreateRental Function},
      label={lst:repository_create_rental_function},
      language=Golang,
]
func (repository CarRentalRepository) CreateRental(rental model.Rental) error {
var newRental = YAMLMapper.ConvertRentalToRentalPersistenceEntity(rental)

repository.Rentals = append(repository.Rentals, newRental)
repository.SaveData()
return nil
}
\end{lstlisting}

\section{The Echo Framework}
\label{sec:the_echo_framework}
\subsection{Definition}
According to its documentation \cite{ECH-DOC}, Echo is an open-source, high-performance, lightweight framework specialized in building web applications in Go.
It is a great choice for building RESTful APIs due to its simple API, powerful routing tools and its middleware support.
Echo was founded in 2015 by LabStack and is maintained until today by the LabStack team and the open-source community.

\subsection{Echo's Use in \texttt{DM-CarV1}}
\texttt{DM-CarV1} uses the echo framework to build a ReSTful API.
This domain microservice was described in \autoref*{sec:domain_microservice_dm_car}.
A code snippet of \texttt{dm-car}'s main function \texttt{main.go} is shown in \autoref{lst:echo_framework_example}.

First, the Echo framework is imported from the \texttt{github.com/labstack/echo/v4} github repository.
This is currently the latest version of the framework.
\texttt{e} is then initialized as a new echo instance.
This is done by calling the \texttt{New()} function on the echo package.
This instance can be used to define routes, include middleware, and start the web server.
In this example, \texttt{controller.RegisterHandlers(e, \&carsResource)} is called to register both \texttt{GET} routes for both the \texttt{GetCar} and \texttt{GetCars} functions.
This is done by calling the \texttt{router.GET} function on the echo package.
The function takes the URL path and the handler function as parameters.
The handler function then is called when the URL path is called.
The last part of the code snippet is used to start the web server.
This is done by calling the \texttt{Start} function on the echo package.
The function takes the port number as a parameter, in this case, it is a formatted string containing the port number.
Then, the server is started by calling the \texttt{Start} function on the echo instance \texttt{e}.
\texttt{e.Logger.Fatal} is a logger object assigned to the echo instance \texttt{e}.
It is used to log errors and messages.
Here it uses the \texttt{Fatal} function to print a fatal error and exit the program if the server cannot be started.

After the server is started, it listens for incoming requests on the specified port.
It then uses the defined routes to handle the incoming requests.
More on the workflow after the server has been started can be found in \autoref*{subsec:echo_basic_workflow}.

\begin{lstlisting}[
      float=h,
      style=kit-cm,
      caption={Echo Framework Example in \texttt{DM-CarV1}},
      label={lst:echo_framework_example},
      language=Golang,
]
// file main.go

package main

import (
	...
	"github.com/labstack/echo/v4"
)

func main() {
inMemoryRepository := infrastructure.InMemoryRepository(...)

carOperations := ...

// Create the CarOperations and the CarController
carsResource := controller.NewCarController(carOperations)

// Register the CarController with the server for handling it's routes
e := echo.New()
controller.RegisterHandlers(e, &carsResource)

// Start the server
portEnv := os.Getenv("PORT")
if portEnv == "" {
      portEnv = "80"
}

var portNumber, err = strconv.Atoi(portEnv)
if err != nil {
      e.Logger.Fatal("The port number configuration is incorrect. Did you set the environment variable PORT?")
}
var port = flag.Int("port", portNumber, "Port for local server")
e.Logger.Fatal(e.Start(fmt.Sprintf("0.0.0.0:%d", *port)))
}
\end{lstlisting}

\subsection{Basic Workflow}
\label{subsec:echo_basic_workflow}
After the server has been started successfully, it listens for incoming requests on the specified port.
It then uses the defined routes to handle the incoming requests.
The basic workflow of the echo framework is as follows.

\paragraph*{1. Request Processing:}
If an incoming request is received, the echo instance checks if the request matches any of the defined routes.
If it does, the echo instance calls the corresponding handler function.
The handler receives a \texttt{Context} instance, containing information about the current request like the parameters of the URL, or the complete URL of the request.
The handler is then executed and returns a response, however, the echo instance does not send the response to the client yet.

\paragraph*{2. Middleware Processing:}
After the handler has been executed, the echo instance checks if any middleware has been defined.
Middleware can be used for tasks such as authentication, logging or error handling.
This allows for easy implementation of these tasks without having to implement them in every handler function.

\paragraph*{3. Response Processing:}
In this step, the echo instance creates a response to be sent back to the client.
This can be an HTML page, a JSON object, or any other type of response.
The echo instance then sends the response back to the client.

\paragraph*{4. Server Continuation:}
The server remains active, waiting for further requests.
If a shutdown is requested manually or an error occurs, the server is stopped and the program is exited.

\subsection{Alternatives to Echo}
This section briefly lists two alternatives to the echo framework.
Both frameworks are used to build web applications and ReSTful APIs in Go and are open source.

\paragraph*{Gin}
Gin is a web framework written in Go.
It is known for its fast and minimalistic design.
Due to its simplicity, it is easy to learn and use.
It also supports middleware and routing, yet it does not provide the variety of middleware and routing tools that echo does.
More on this topic can be found in Gin's documentation \cite{GIN-DOC}.

\paragraph*{Iris}
Iris also is a web framework written in Go.
It is feature-rich and provides a lot of tools for building web applications, thus being more complex than Gin and Echo.
It also provides a lot of middleware and routing tools.
Also, due to its complexity, it may have a bigger overhead and therefore less performance than Gin and Echo.
More on this topic can be found in Iris' documentation \cite{IRI-DOC}.
